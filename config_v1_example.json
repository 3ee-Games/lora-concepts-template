{
  "pretrained_model_name_or_path": "C:/example/stable-diffusion-webui/models/Stable-diffusion/sd15_pruned.ckpt",
  "v2": false,
  "v_parameterization": false,
  "logging_dir": "C:\\example\\lora\\log",
  "train_data_dir": "C:\\example\\lora\\image_dir",
  "reg_data_dir": "C:\\example\\lora\\reg_dir",
  "output_dir": "C:\\example\\lora\\output",
  "max_resolution": "512,512",
  "learning_rate": "1e-5",
  "lr_scheduler": "constant_with_warmup",
  "lr_warmup": "10",
  "train_batch_size": 8,
  "epoch": "1",
  "save_every_n_epochs": "1",
  "mixed_precision": "bf16",
  "save_precision": "bf16",
  "seed": "69234",
  "num_cpu_threads_per_process": 8,
  "cache_latents": true,
  "caption_extension": "txt",
  "enable_bucket": true,
  "gradient_checkpointing": false,
  "full_fp16": false,
  "no_token_padding": false,
  "stop_text_encoder_training": 0,
  "use_8bit_adam": true,
  "xformers": true,
  "save_model_as": "safetensors",
  "shuffle_caption": false,
  "save_state": false,
  "resume": "",
  "prior_loss_weight": 1.0,
  "text_encoder_lr": "5e-5",
  "unet_lr": "1e-3",
  "network_dim": 128,
  "lora_network_weights": "",
  "color_aug": false,
  "flip_aug": false,
  "clip_skip": 2,
  "gradient_accumulation_steps": 1.0,
  "mem_eff_attn": false,
  "output_name": "example_lora_template",
  "model_list": [],
  "max_token_length": "75",
  "max_train_epochs": "",
  "max_data_loader_n_workers": "",
  "network_alpha": 1,
  "training_comment": "",
  "keep_tokens": "0",
  "lr_scheduler_num_cycles": "",
  "lr_scheduler_power": "",
  "persistent_data_loader_workers": false,
  "bucket_no_upscale": true,
  "random_crop": false,
  "bucket_reso_steps": 64.0
}